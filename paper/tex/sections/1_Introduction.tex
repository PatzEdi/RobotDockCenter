\section{Introduction}
Robot docking is a fundamental task in autonomous systems, enabling robots to recharge and continue operations without human intervention. Traditional docking solutions rely on multiple sensors such as LIDAR, ultrasonic sensors, and cameras \citep{app131910675}. While effective, these approaches increase hardware complexity and cost.

Reinforcement learning has gained popularity in robotic control, but it often requires extensive training, computational resources, reward function optimization, and at times compromises when implementing them in low-cost systems \citep{Deisenroth2012}. These challenges make reinforcement learning impractical for resource-constrained robots that need a way to dock and charge.

To address these limitations, we propose an alternative approach that utilizes monocular vision and supervised learning to achieve reliable docking without additional sensors or reinforcement learning. Our method predicts docking actions from a single input frame, identifying two key targets: one for alignment and the other representing the docking station.

We use the Godot game engine to generate synthetic training data, capturing diverse docking scenarios. A deep learning model, implemented in PyTorch, is trained on these images to make high-frequency predictions. The model is lightweight, allowing real-time inference on low-power hardware, such as a Raspberry Pi \citep{ameen2023optimizingdeeplearningmodels}. A Flask server facilitates communication between the trained model and the robotâ€™s virtual control system for integration into a simulated docking environment.

Our results suggest that monocular vision-based docking is a feasible alternative to sensor-heavy and reinforcement learning-based approaches. This method offers a cost-effective and computationally efficient solution for autonomous docking, with potential for real-world deployment.

The paper is structured as follows. After going over related work, we go in depth regarding our methodology, which includes data generation, data preprocessing, model architecture, training, inference, and Flask server integration. We then present our results and discuss the possible implications of our work. We then conclude our paper with a discussion on the limitations of our work and potential future directions.
